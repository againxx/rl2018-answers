# Exercises of  Chapter 05

## 5.5
#### Ex5.5 考虑只有一个非终止状态和一个单一动作的马尔科夫决策过程, 动作设定为: 以概率$p$跳回非终止状态, 以概率$1-p$转移到终止状态. 令每一时刻所有转移的收益都为$+1$, 且$\gamma=1$. 假设你观察到一幕序列持续了10个时刻, 获得了值为10的回报. 则对这个非终止状态的首次访问型和每次访问型的价值估计分别是什么?
解: 对于首次访问型, 仅仅考虑$S_0$时刻的估计, 即$V(S_0) = G_0 = 10$

对于每次访问型, 需要考虑除最后时刻外的所有时刻的估计
$$ V(S) = \frac{1}{10} (G_0 + G_1 + \cdots + G_9) = \frac{10 + 9 + \cdots + 1}{10} = 5.5 $$

#### Ex5.6 给定用$b$生成的回报, 类比公式(5.6), 用动作价值函数$Q(s, a)$替代状态价值函数$V(s)$, 得到的式子是什么?
解:
$$ \mathbb{E}_b [\rho_{t+1:T-1} G_t | S_t = s, A_t = a] = q_\pi(s, a) $$

故加权重要度采样估计的$Q(s, a)$为
$$
Q(s, a) = \frac{\sum_{t \in {\large\tau}(s, a)}\rho_{t+1:T(t)-1} G_t}{\sum_{t \in {\large\tau}(s, a)}\rho_{t+1:T(t)-1}}
$$
其中${\large\tau}(s,a)$为所有访问过状态$s$并选择动作$a$的时刻的集合

#### Ex5.7 实际在使用普通重要度采样时, 与图5.3所示的学习曲线一样, 错误率随着训练一般都是下降的. 但是对于加权重要度采样, 错误率会先上升然后下降. 为什么会这样?
